ğŸ§  Segundo DesafÃ­o - Telecom X
La empresa Telecom X busca anticiparse al problema del abandono de clientes.
El objetivo es desarrollar modelos predictivos capaces de prever quÃ© clientes tienen mayor probabilidad de cancelar sus servicios.

ğŸ“Š ExtracciÃ³n y VisualizaciÃ³n de los Datos
Se carga el DataFrame df, con 7267 filas y 21 columnas.

Se realiza una inspecciÃ³n inicial para entender la estructura y calidad de los datos.

ğŸ“‰ CÃ¡lculo de Clases
Se determina que un 25.7% de los clientes ha abandonado el servicio.

Esto refleja un desbalance de clases, lo cual debe ser considerado al modelar.

ğŸ§¹ PreparaciÃ³n de los Datos para el Modelado
ğŸ› ï¸ Feature Engineering
â• CreaciÃ³n de nuevas variables
Se crea la variable Gasto_mensual_antiguedad como combinaciÃ³n de:

Cuentas_diarias

Antiguedad_meses

Esta variable refleja el gasto mensual relativo a la antigÃ¼edad del cliente.

â– EliminaciÃ³n de columnas irrelevantes
Se utiliza mutual_info_classif para calcular la InformaciÃ³n Mutua (MI).

Se eliminan las variables con menor MI por su bajo aporte al anÃ¡lisis del churn.

ğŸ“Œ Variables Seleccionadas para el Modelado
Abandono_cliente

Antiguedad_meses

Seguridad_en_lÃ­nea_Internet

Tipo_de_contrato

Metodo_de_pago

Gasto_diario_antiguedad

ğŸ”„ VerificaciÃ³n de CorrelaciÃ³n entre Variables
Se aplicÃ³ el Ã­ndice VIF (Variance Inflation Factor):

Todos los valores < 5 â†’ no hay multicolinealidad.

Se utilizÃ³ correlaciÃ³n de Pearson para detectar posibles fugas de datos.

ğŸ“Œ El DataFrame final utilizado se llama: datos_reducido.

ğŸ¯ Baseline: Modelo Predictivo Base
Se construyÃ³ un modelo DummyClassifier como lÃ­nea base.

Score del modelo Dummy: 0.7560 (accuracy al predecir siempre la clase mayoritaria).

ğŸ¤– CreaciÃ³n de Modelos Predictivos
Se desarrollaron tres modelos supervisados:

KNN

Decision Tree

Random Forest

Cada modelo fue:

Implementado con Pipeline usando sklearn o imblearn.

Mejorado mediante:

Ajuste de hiperparÃ¡metros.

OptimizaciÃ³n del umbral.

OptimizaciÃ³n del Recall (minimizar falsos negativos).

ğŸ“Š ComparaciÃ³n de los Mejores Modelos
Modelo	Umbral	Accuracy	Precision (Clase 1)	Recall (Clase 1)	F1-score	AUC
KNN	0.22	0.6391	0.4065	0.8764	0.5553	0.7960
DT	0.22	0.5577	0.3620	0.9438	0.5233	0.8158
RF	0.22	0.5814	0.3757	0.9486	0.5383	0.8313

ğŸ† Mejor modelo: Random Forest (RF3) â†’ pipe_rfopt

ğŸ§ª EvaluaciÃ³n de Nuevos Clientes
Se implementÃ³ un sistema para evaluar nuevos clientes individuales.

TambiÃ©n se desarrollÃ³ cÃ³digo para predecir el abandono de mÃºltiples clientes en lote.

ğŸ“ˆ VisualizaciÃ³n de Tendencias del Abandono
Se generaron tres visualizaciones clave:

ğŸ“¦ Boxplot: AntigÃ¼edad vs Tipo de Contrato vs Abandono

ğŸ’¸ GrÃ¡fico de Gasto Diario por AntigÃ¼edad segÃºn Abandono_cliente

ğŸ”µ Scatterplot: AntigÃ¼edad vs Gasto Diario, por CancelaciÃ³n y Tipo de Contrato

ğŸ§¬ Importancia de las Variables
Usando Random Forest, se calculÃ³ la importancia relativa de cada variable.

Gasto_diario_antiguedad fue la variable mÃ¡s relevante, con un peso de aproximadamente 0.65.

âš–ï¸ CÃ¡lculo del Odds Ratio
Se utilizÃ³ el odds ratio para cuantificar la probabilidad de abandono en distintos grupos.

Se comparan odds de abandono entre grupos expuestos y no expuestos a variables como tipo de contrato, gasto, etc.

âœ… ConclusiÃ³n
Gasto_diario_antiguedad es el predictor mÃ¡s potente del abandono (OR â‰ˆ 8.2).

Le siguen:

Tipo de contrato

AntigÃ¼edad del cliente

El modelo Random Forest optimizado (pipe_rfopt) ofrece el mejor balance entre precisiÃ³n y recall.

ğŸ§° Herramientas Utilizadas
Proyecto desarrollado en Python con las siguientes bibliotecas:

pandas, numpy

matplotlib, seaborn

sklearn: selecciÃ³n de variables, modelado, pipelines, mÃ©tricas, validaciÃ³n

imblearn: balanceo con SMOTE y pipelines

statsmodels: VIF

scipy.stats: bÃºsqueda aleatoria de hiperparÃ¡metros

ğŸ‘¤ Autor
Gabriel MÃ©ndez Oteiza
Proyecto desarrollado como parte del desafÃ­o de anÃ¡lisis y predicciÃ³n del abandono de clientes en Telecom X.

